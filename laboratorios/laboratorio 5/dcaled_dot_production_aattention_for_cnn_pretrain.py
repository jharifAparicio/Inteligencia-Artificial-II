# -*- coding: utf-8 -*-
"""dcaled dot production aattention for cnn pretrain.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xidb7zZX5_tdDhyhQwJkAQtP2omoqK-y
"""

import torch

# Determina si hay una GPU disponible y usa CUDA si es así.
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f'Usando el dispositivo: {device}')

import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random

dataset_path = "/content/drive/MyDrive/USFX/INTELIGENCIA ARTIFICIAL II/practicas/practica 1 dataset/residuos_solidos"
# Listar las subcarpetas (clases)
clases = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]
print("Clases encontradas:", clases)

# Listar clases
clases = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]
print("Clases encontradas:", clases)

# Mostrar una imagen de cada clase
for clase in clases:
    # Buscar subcarpetas dentro de la clase
    subcarpetas = [d for d in os.listdir(os.path.join(dataset_path, clase))
                   if os.path.isdir(os.path.join(dataset_path, clase, d))]

    # Tomar la primera subcarpeta (si hay más de una)
    subcarpeta = subcarpetas[0] if subcarpetas else ''

    # Listar imágenes dentro de la subcarpeta
    imagenes = [f for f in os.listdir(os.path.join(dataset_path, clase, subcarpeta))
                if f.endswith(('.jpg', '.png', '.jpeg'))]

    if not imagenes:
        continue  # Saltar si no hay imágenes

    # Seleccionar imagen aleatoria
    imagen_aleatoria = random.choice(imagenes)

    # Ruta completa
    imagen_path = os.path.join(dataset_path, clase, subcarpeta, imagen_aleatoria)

    # Cargar y mostrar
    img = mpimg.imread(imagen_path)
    plt.imshow(img)
    plt.title(f"Clase: {clase}")
    plt.axis('off')
    plt.show()

import os
import matplotlib.pyplot as plt

classes = ['restos_de_hilos', 'cascara_de_huevos', 'envases_de_vidrio', 'retasos_de_telas', 'mates_de_sopar']

# Contar imágenes por clase (solo JPG)
counts = []
for c in classes:
    class_folder = os.path.join(dataset_path, c)  # carpeta interna con las imágenes
    num_imgs = len([f for f in os.listdir(class_folder) if f.lower().endswith('.jpg')])
    counts.append(num_imgs)
    print(f"{c}: {num_imgs} imágenes")

# Graficar
plt.bar(classes, counts)
plt.title("Distribución de clases")
plt.ylabel("Número de imágenes")
plt.show()

from PIL import Image

class PadToSquare:
    def __init__(self, fill=0):
        self.fill = fill

    def __call__(self, img: Image.Image):
        w, h = img.size
        max_side = max(w, h)
        pad_left = (max_side - w) // 2
        pad_top = (max_side - h) // 2
        pad_right = max_side - w - pad_left
        pad_bottom = max_side - h - pad_top
        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom), fill=self.fill)

image_transforms = transforms.Compose([
    PadToSquare(fill=0),                   # rellena con negro para cuadrar la imagen
    transforms.Resize((224, 224)),         # luego redimensiona exactamente a 224x224
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# --- Carga del dataset ---
full_dataset = datasets.ImageFolder(root=dataset_path, transform=image_transforms)

# --- División en 80/10/10 ---
total_size = len(full_dataset)
train_size = int(0.8 * total_size)
val_size = int(0.1 * total_size)
test_size = total_size - train_size - val_size

train_dataset, val_dataset, test_dataset = random_split(
    full_dataset,
    [train_size, val_size, test_size],
    generator=torch.Generator().manual_seed(42)  # reproducible
)

# --- DataLoaders ---
batch_size = 16  # ajusta según tu GPU
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

print("Dataset cargado y dividido correctamente.")
print(f"Conjunto de entrenamiento: {len(train_dataset)} imágenes")
print(f"Conjunto de validación: {len(val_dataset)} imágenes")
print(f"Conjunto de prueba: {len(test_dataset)} imágenes")

!pip install pytorch-lightning
!pip install torchtext

import torch
import torch.nn as nn
import torch.nn.functional as F
import pytorch_lightning as pl
from torchvision import models

class CNNPretrain(pl.LightningModule):
    def __init__(self, fine_tune=False, lr=3e-3):
        super().__init__()
        self.lr = lr

        # CNN preentrenada
        self.cnn = models.mnasnet1_0(pretrained=True)
        self.features = nn.Sequential(*list(self.cnn.children())[:-1])
        self.feature_dim = 1280

        if not fine_tune:
            for p in self.features.parameters():
                p.requires_grad = False

    def forward(self, x):
        return self.features(x)  # (B, F, H, W)

    # predict
    def predict(self, x):
        with torch.no_grad():
            y_hat = self(x)
            return torch.argmax(y_hat, axis=1)

    # compute_loss_and_acc
    def compute_loss_and_acc(self, batch):
        x, y = batch
        y_hat = self(x)
        loss = F.cross_entropy(y_hat, y)
        acc = (torch.argmax(y_hat, axis=1) == y).sum().item() / y.shape[0]
        return loss, acc

    # training_step
    def training_step(self, batch, batch_idx):
        loss, acc = self.compute_loss_and_acc(batch)
        self.log('train_loss', loss)
        self.log('train_acc', acc, prog_bar=True)
        return loss

    # validation_step
    def validation_step(self, batch, batch_idx):
        loss, acc = self.compute_loss_and_acc(batch)
        self.log('val_loss', loss, prog_bar=True)
        self.log('val_acc', acc, prog_bar=True)

    # optimizador
    def configure_optimizers(self):
        return torch.optim.Adam(filter(lambda p: p.requires_grad, self.parameters()), lr=self.lr)

import math
import torch.nn as nn

class ScaledDotSelfAttention(nn.Module):
    def __init__(self, n_embd):
        super().__init__()
        self.key = nn.Linear(n_embd, n_embd)
        self.query = nn.Linear(n_embd, n_embd)
        self.value = nn.Linear(n_embd, n_embd)

    def forward(self, x):
        B, L, F_dim = x.size()
        k = self.key(x)
        q = self.query(x)
        v = self.value(x)
        att = (q @ k.transpose(1,2)) / math.sqrt(F_dim)
        att = nn.functional.softmax(att, dim=-1)
        y = att @ v
        return y

class Model(CNNPretrain):
    def __init__(self, num_classes=5, fine_tune=False, lr=3e-3):
        super().__init__(fine_tune=fine_tune, lr=lr)
        self.attn = ScaledDotSelfAttention(self.feature_dim)
        self.fc = nn.Linear(self.feature_dim, num_classes)

    def forward(self, x):
        B = x.size(0)

        # 1️⃣ Extraer características de la CNN
        features = super().forward(x)  # shape: (B, F, H, W)
        F_dim, H, W = features.size(1), features.size(2), features.size(3)
        seq_len = H * W

        # 2️⃣ Crear patches explícitos
        # Cada patch es un vector de F_dim features
        # reshape y permute para obtener (B, seq_len, F_dim)
        patches = features.view(B, F_dim, seq_len).permute(0, 2, 1)
        # patches.shape = (B, seq_len, F_dim)

        # 3️⃣ Aplicar atención sobre los patches
        attn_out = self.attn(patches)  # (B, seq_len, F_dim)

        # 4️⃣ Pooling: agregamos todos los patches para un vector por imagen
        pooled = attn_out.mean(dim=1)  # (B, F_dim)

        # 5️⃣ Clasificación final
        out = self.fc(pooled)  # (B, num_classes)
        return out

import torch
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Asegúrate de que tu modelo esté en modo evaluación
model.eval()

all_preds = []
all_labels = []

# No necesitamos gradientes para test
with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(model.device)  # si estás usando GPU
        labels = labels.to(model.device)

        outputs = model(images)
        preds = torch.argmax(outputs, dim=1)

        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# --- Matriz de confusión ---
cm = confusion_matrix(all_labels, all_preds)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=full_dataset.classes)

# --- Visualizar ---
disp.plot(cmap=plt.cm.Blues)
plt.title("Matriz de Confusión")
plt.show()